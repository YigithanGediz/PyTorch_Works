{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from torch.utils.data import DataLoader\n",
    "from Models import *\n",
    "from helpers import *\n",
    "from math import ceil\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# You can get the data from https://www.kaggle.com/puneet6060/intel-image-classification\n",
    "train_dir = \"../Data/seg_train/\"\n",
    "test_dir = \"../Data/seg_train/\"\n",
    "valid_dir = \"../Data/seg_pred/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5), # randomly flip and rotate\n",
    "    transforms.ColorJitter(0.3,0.4,0.4,0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.425, 0.415, 0.405), (0.205, 0.205, 0.205))\n",
    "    ])\n",
    "\n",
    "# Augmentation on test images not needed\n",
    "transform_tests = torchvision.transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.425, 0.415, 0.405), (0.255, 0.245, 0.235))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14034, 150, 150, 3)\n"
     ]
    }
   ],
   "source": [
    "train_images, train_labels, train_label_decoder = get_images(train_dir)\n",
    "test_images, test_labels, test_label_decoder = get_images(test_dir)\n",
    "print(train_images.shape)\n",
    "\n",
    "for i in range(6):\n",
    "    assert train_label_decoder[i] == test_label_decoder[i]\n",
    "\n",
    "\n",
    "\n",
    "train_data = ImageDataset(train_images, train_labels, transform=transform)\n",
    "test_data = ImageDataset(test_images, test_labels, transform=transform_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 150, 150])\n",
      "tensor(0)\n"
     ]
    }
   ],
   "source": [
    "sample = train_data[0]\n",
    "print(sample[0].shape)\n",
    "print(sample[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = ResnetTrained(train_resnet = True, pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "batch_size=8\n",
    "total_samples = len(train_data)\n",
    "test_samples = len(test_data)\n",
    "n_iterations = ceil(total_samples / batch_size)\n",
    "learning_rate = 1e-3\n",
    "num_epochs = 80\n",
    "save_Dir = \"../Models/\"\n",
    "vol = 4\n",
    "\n",
    "train_loader = DataLoader(train_data,batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, iteration 0, loss 1.7128022909164429\n",
      "Epoch 1, iteration 200, loss 1.6483718156814575\n",
      "Epoch 1, iteration 400, loss 1.5186982154846191\n",
      "Epoch 1, iteration 600, loss 1.161478042602539\n",
      "Epoch 1, iteration 800, loss 1.5223408937454224\n",
      "Epoch 1, iteration 1000, loss 1.0517964363098145\n",
      "Epoch 1, iteration 1200, loss 1.5515552759170532\n",
      "Epoch 1, iteration 1400, loss 1.6349611282348633\n",
      "Epoch 1, iteration 1600, loss 1.6848281621932983\n",
      "Epoch 2, loss: 1.4484312534332275, accuracy 40.280746757873736\n",
      "Epoch 2, iteration 0, loss 1.0488035678863525\n",
      "Epoch 2, iteration 200, loss 2.033801317214966\n",
      "Epoch 2, iteration 400, loss 1.5869107246398926\n",
      "Epoch 2, iteration 600, loss 1.7770636081695557\n",
      "Epoch 2, iteration 800, loss 1.3646612167358398\n",
      "Epoch 2, iteration 1000, loss 1.4098716974258423\n",
      "Epoch 2, iteration 1200, loss 1.1804001331329346\n",
      "Epoch 2, iteration 1400, loss 1.2899599075317383\n",
      "Epoch 2, iteration 1600, loss 1.4500566720962524\n",
      "Epoch 3, loss: 1.6844611167907715, accuracy 34.49479834687188\n",
      "Epoch 3, iteration 0, loss 1.7024248838424683\n",
      "Epoch 3, iteration 200, loss 1.3990436792373657\n",
      "Epoch 3, iteration 400, loss 1.251300573348999\n",
      "Epoch 3, iteration 600, loss 1.0600957870483398\n",
      "Epoch 3, iteration 800, loss 1.1731253862380981\n",
      "Epoch 3, iteration 1000, loss 1.43215012550354\n",
      "Epoch 3, iteration 1200, loss 1.2623844146728516\n",
      "Epoch 3, iteration 1400, loss 1.650991439819336\n",
      "Epoch 3, iteration 1600, loss 1.5093544721603394\n",
      "Epoch 4, loss: 1.0775772333145142, accuracy 46.209206213481544\n",
      "Epoch 4, iteration 0, loss 1.020320177078247\n",
      "Epoch 4, iteration 200, loss 1.409577488899231\n",
      "Epoch 4, iteration 400, loss 1.4624196290969849\n",
      "Epoch 4, iteration 600, loss 1.5003961324691772\n",
      "Epoch 4, iteration 800, loss 1.4677873849868774\n",
      "Epoch 4, iteration 1000, loss 0.7685301303863525\n",
      "Epoch 4, iteration 1200, loss 1.2935664653778076\n",
      "Epoch 4, iteration 1400, loss 1.3235416412353516\n",
      "Epoch 4, iteration 1600, loss 0.9596899747848511\n",
      "Epoch 5, loss: 2.8174896240234375, accuracy 49.90024226877583\n",
      "Epoch 5, iteration 0, loss 1.0522756576538086\n",
      "Epoch 5, iteration 200, loss 1.2306556701660156\n",
      "Epoch 5, iteration 400, loss 1.2992396354675293\n",
      "Epoch 5, iteration 600, loss 0.9357086420059204\n",
      "Epoch 5, iteration 800, loss 1.3956904411315918\n",
      "Epoch 5, iteration 1000, loss 1.5503661632537842\n",
      "Epoch 5, iteration 1200, loss 0.9518384337425232\n",
      "Epoch 5, iteration 1400, loss 1.114348292350769\n",
      "Epoch 5, iteration 1600, loss 1.0300440788269043\n",
      "Epoch 6, loss: 0.9330902695655823, accuracy 53.491520592845944\n",
      "Epoch 6, iteration 0, loss 0.9920651316642761\n",
      "Epoch 6, iteration 200, loss 1.6645393371582031\n",
      "Epoch 6, iteration 400, loss 0.765288233757019\n",
      "Epoch 6, iteration 600, loss 1.3745760917663574\n",
      "Epoch 6, iteration 800, loss 1.1171555519104004\n",
      "Epoch 6, iteration 1000, loss 0.8901833295822144\n",
      "Epoch 6, iteration 1200, loss 1.076965570449829\n",
      "Epoch 6, iteration 1400, loss 1.1636139154434204\n",
      "Epoch 6, iteration 1600, loss 1.0735429525375366\n",
      "Epoch 7, loss: 1.2092502117156982, accuracy 58.20863616930312\n",
      "Epoch 7, iteration 0, loss 1.4111251831054688\n",
      "Epoch 7, iteration 200, loss 1.4120416641235352\n",
      "Epoch 7, iteration 400, loss 0.7811253666877747\n",
      "Epoch 7, iteration 600, loss 1.4386335611343384\n",
      "Epoch 7, iteration 800, loss 0.8167518377304077\n",
      "Epoch 7, iteration 1000, loss 1.2765748500823975\n",
      "Epoch 7, iteration 1200, loss 0.9213886260986328\n",
      "Epoch 7, iteration 1400, loss 0.6811442971229553\n",
      "Epoch 7, iteration 1600, loss 1.0438109636306763\n",
      "Epoch 8, loss: 0.7807604670524597, accuracy 60.34630183839248\n",
      "Epoch 8, iteration 0, loss 1.0849744081497192\n",
      "Epoch 8, iteration 200, loss 1.1138334274291992\n",
      "Epoch 8, iteration 400, loss 1.2077053785324097\n",
      "Epoch 8, iteration 600, loss 1.0135952234268188\n",
      "Epoch 8, iteration 800, loss 0.9744272828102112\n",
      "Epoch 8, iteration 1000, loss 0.8560203909873962\n",
      "Epoch 8, iteration 1200, loss 0.9091799855232239\n",
      "Epoch 8, iteration 1400, loss 0.7423902750015259\n",
      "Epoch 8, iteration 1600, loss 1.9160728454589844\n",
      "Epoch 9, loss: 1.2707781791687012, accuracy 63.04688613367536\n",
      "Epoch 9, iteration 0, loss 1.1335264444351196\n",
      "Epoch 9, iteration 200, loss 0.6690112948417664\n",
      "Epoch 9, iteration 400, loss 0.9601800441741943\n",
      "Epoch 9, iteration 600, loss 0.8871331810951233\n",
      "Epoch 9, iteration 800, loss 0.6478655338287354\n",
      "Epoch 9, iteration 1000, loss 1.549340009689331\n",
      "Epoch 9, iteration 1200, loss 0.6319262385368347\n",
      "Epoch 9, iteration 1400, loss 1.1936148405075073\n",
      "Epoch 9, iteration 1600, loss 0.43106576800346375\n",
      "Epoch 10, loss: 1.2378320693969727, accuracy 67.8993872025082\n",
      "Epoch 10, iteration 0, loss 1.9148645401000977\n",
      "Epoch 10, iteration 200, loss 0.7641565799713135\n",
      "Epoch 10, iteration 400, loss 0.5322667360305786\n",
      "Epoch 10, iteration 600, loss 0.8653826117515564\n",
      "Epoch 10, iteration 800, loss 0.7539860010147095\n",
      "Epoch 10, iteration 1000, loss 1.0592252016067505\n",
      "Epoch 10, iteration 1200, loss 1.1704373359680176\n",
      "Epoch 10, iteration 1400, loss 0.784763514995575\n",
      "Epoch 10, iteration 1600, loss 1.4430854320526123\n",
      "Epoch 11, loss: 0.7041279673576355, accuracy 68.98247114151347\n",
      "Epoch 11, iteration 0, loss 1.1581732034683228\n",
      "Epoch 11, iteration 200, loss 1.4579682350158691\n",
      "Epoch 11, iteration 400, loss 1.0170191526412964\n",
      "Epoch 11, iteration 600, loss 1.2853879928588867\n",
      "Epoch 11, iteration 800, loss 0.5224777460098267\n",
      "Epoch 11, iteration 1000, loss 0.5888378024101257\n",
      "Epoch 11, iteration 1200, loss 0.8322266340255737\n",
      "Epoch 11, iteration 1400, loss 0.3661518394947052\n",
      "Epoch 11, iteration 1600, loss 0.5430283546447754\n",
      "Epoch 12, loss: 0.22144433856010437, accuracy 69.44563203648283\n",
      "Epoch 12, iteration 0, loss 0.9727029204368591\n",
      "Epoch 12, iteration 200, loss 0.9577310085296631\n",
      "Epoch 12, iteration 400, loss 1.0748014450073242\n",
      "Epoch 12, iteration 600, loss 1.3602399826049805\n",
      "Epoch 12, iteration 800, loss 0.8824236392974854\n",
      "Epoch 12, iteration 1000, loss 0.650283694267273\n",
      "Epoch 12, iteration 1200, loss 1.0802429914474487\n",
      "Epoch 12, iteration 1400, loss 0.6510052680969238\n",
      "Epoch 12, iteration 1600, loss 0.5785841345787048\n",
      "Epoch 13, loss: 0.48826709389686584, accuracy 72.153341883996\n",
      "Epoch 13, iteration 0, loss 0.7823531627655029\n",
      "Epoch 13, iteration 200, loss 0.5557586550712585\n",
      "Epoch 13, iteration 400, loss 0.47637832164764404\n",
      "Epoch 13, iteration 600, loss 0.5091267228126526\n",
      "Epoch 13, iteration 800, loss 0.953433632850647\n",
      "Epoch 13, iteration 1000, loss 0.4871746599674225\n",
      "Epoch 13, iteration 1200, loss 1.21683669090271\n",
      "Epoch 13, iteration 1400, loss 0.4527207612991333\n",
      "Epoch 13, iteration 1600, loss 0.560574471950531\n",
      "Epoch 14, loss: 1.5793766975402832, accuracy 74.29813310531566\n",
      "Epoch 14, iteration 0, loss 0.3230363130569458\n",
      "Epoch 14, iteration 200, loss 0.7881741523742676\n",
      "Epoch 14, iteration 400, loss 0.902482807636261\n",
      "Epoch 14, iteration 600, loss 0.5078690648078918\n",
      "Epoch 14, iteration 800, loss 1.24183189868927\n",
      "Epoch 14, iteration 1000, loss 0.4341397285461426\n",
      "Epoch 14, iteration 1200, loss 1.0853614807128906\n",
      "Epoch 14, iteration 1400, loss 0.8055432438850403\n",
      "Epoch 14, iteration 1600, loss 0.5966439247131348\n",
      "Epoch 15, loss: 2.366593599319458, accuracy 71.70443209348724\n",
      "Epoch 15, iteration 0, loss 1.1755681037902832\n",
      "Epoch 15, iteration 200, loss 0.6746078729629517\n",
      "Epoch 15, iteration 400, loss 0.7928640246391296\n",
      "Epoch 15, iteration 600, loss 0.41653627157211304\n",
      "Epoch 15, iteration 800, loss 0.7538590431213379\n",
      "Epoch 15, iteration 1000, loss 0.5737636685371399\n",
      "Epoch 15, iteration 1200, loss 0.8503227829933167\n",
      "Epoch 15, iteration 1400, loss 0.7336095571517944\n",
      "Epoch 15, iteration 1600, loss 0.31127500534057617\n",
      "Epoch 16, loss: 3.8592870235443115, accuracy 75.06769274618783\n",
      "Epoch 16, iteration 0, loss 0.43916288018226624\n",
      "Epoch 16, iteration 200, loss 1.3234076499938965\n",
      "Epoch 16, iteration 400, loss 0.49716031551361084\n",
      "Epoch 16, iteration 600, loss 0.4494181275367737\n",
      "Epoch 16, iteration 800, loss 0.4896749258041382\n",
      "Epoch 16, iteration 1000, loss 0.8755379915237427\n",
      "Epoch 16, iteration 1200, loss 0.7393388748168945\n",
      "Epoch 16, iteration 1400, loss 0.6014869809150696\n",
      "Epoch 16, iteration 1600, loss 1.0802903175354004\n",
      "Epoch 17, loss: 0.14489421248435974, accuracy 77.06284737067122\n",
      "Epoch 17, iteration 0, loss 0.5729835033416748\n",
      "Epoch 17, iteration 200, loss 0.9715652465820312\n",
      "Epoch 17, iteration 400, loss 0.37128201127052307\n",
      "Epoch 17, iteration 600, loss 0.37366169691085815\n",
      "Epoch 17, iteration 800, loss 0.21407893300056458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, iteration 1000, loss 0.7048323154449463\n",
      "Epoch 17, iteration 1200, loss 1.0725126266479492\n",
      "Epoch 17, iteration 1400, loss 0.67765212059021\n",
      "Epoch 17, iteration 1600, loss 1.7228186130523682\n",
      "Epoch 18, loss: 3.5666487216949463, accuracy 77.8181559070828\n",
      "Epoch 18, iteration 0, loss 0.4328455328941345\n",
      "Epoch 18, iteration 200, loss 1.259771466255188\n",
      "Epoch 18, iteration 400, loss 0.33956217765808105\n",
      "Epoch 18, iteration 600, loss 0.8445342183113098\n",
      "Epoch 18, iteration 800, loss 0.6283143162727356\n",
      "Epoch 18, iteration 1000, loss 0.6852893829345703\n",
      "Epoch 18, iteration 1200, loss 1.1479554176330566\n",
      "Epoch 18, iteration 1400, loss 1.4264808893203735\n",
      "Epoch 18, iteration 1600, loss 0.6744024157524109\n",
      "Epoch 19, loss: 1.1787701845169067, accuracy 76.8205785948411\n",
      "Epoch 19, iteration 0, loss 0.2949470281600952\n",
      "Epoch 19, iteration 200, loss 0.28058335185050964\n",
      "Epoch 19, iteration 400, loss 1.1693781614303589\n",
      "Epoch 19, iteration 600, loss 0.5100911855697632\n",
      "Epoch 19, iteration 800, loss 0.582497239112854\n",
      "Epoch 19, iteration 1000, loss 0.9351392388343811\n",
      "Epoch 19, iteration 1200, loss 0.36310404539108276\n",
      "Epoch 19, iteration 1400, loss 1.5193181037902832\n",
      "Epoch 19, iteration 1600, loss 1.5197590589523315\n",
      "Epoch 20, loss: 3.5547091960906982, accuracy 79.08650420407582\n",
      "Epoch 20, iteration 0, loss 0.5623819231987\n",
      "Epoch 20, iteration 200, loss 1.0020288228988647\n",
      "Epoch 20, iteration 400, loss 0.22433361411094666\n",
      "Epoch 20, iteration 600, loss 0.6559913754463196\n",
      "Epoch 20, iteration 800, loss 0.3432024419307709\n",
      "Epoch 20, iteration 1000, loss 0.2075493484735489\n",
      "Epoch 20, iteration 1200, loss 0.6352107524871826\n",
      "Epoch 20, iteration 1400, loss 0.7337554097175598\n",
      "Epoch 20, iteration 1600, loss 0.4903765618801117\n",
      "Epoch 21, loss: 0.07099688798189163, accuracy 78.33119566766425\n",
      "Epoch 21, iteration 0, loss 0.6483575105667114\n",
      "Epoch 21, iteration 200, loss 0.4494655430316925\n",
      "Epoch 21, iteration 400, loss 0.15290211141109467\n",
      "Epoch 21, iteration 600, loss 0.3356565237045288\n",
      "Epoch 21, iteration 800, loss 1.0098072290420532\n",
      "Epoch 21, iteration 1000, loss 0.35099518299102783\n",
      "Epoch 21, iteration 1200, loss 0.30755916237831116\n",
      "Epoch 21, iteration 1400, loss 1.0624581575393677\n",
      "Epoch 21, iteration 1600, loss 0.7880093455314636\n",
      "Epoch 22, loss: 4.028212547302246, accuracy 78.66609662248824\n",
      "Epoch 22, iteration 0, loss 0.8232699632644653\n",
      "Epoch 22, iteration 200, loss 0.6110403537750244\n",
      "Epoch 22, iteration 400, loss 0.1391267031431198\n",
      "Epoch 22, iteration 600, loss 0.3017430305480957\n",
      "Epoch 22, iteration 800, loss 0.46831631660461426\n",
      "Epoch 22, iteration 1000, loss 0.20941254496574402\n",
      "Epoch 22, iteration 1200, loss 0.8492221832275391\n",
      "Epoch 22, iteration 1400, loss 0.653551459312439\n",
      "Epoch 22, iteration 1600, loss 0.6750441789627075\n",
      "Epoch 23, loss: 0.10107532888650894, accuracy 80.09120706854782\n",
      "80.09120706854782 is higher than the max 79.08650420407582\n",
      "Epoch 23, iteration 0, loss 0.24573156237602234\n",
      "Epoch 23, iteration 200, loss 0.15897759795188904\n",
      "Epoch 23, iteration 400, loss 0.26305699348449707\n",
      "Epoch 23, iteration 600, loss 1.127681016921997\n",
      "Epoch 23, iteration 800, loss 0.571672797203064\n",
      "Epoch 23, iteration 1000, loss 0.439175009727478\n",
      "Epoch 23, iteration 1200, loss 0.3057972192764282\n",
      "Epoch 23, iteration 1400, loss 0.8475947380065918\n",
      "Epoch 23, iteration 1600, loss 0.44647085666656494\n",
      "Epoch 24, loss: 0.25002628564834595, accuracy 80.22659256092348\n",
      "80.22659256092348 is higher than the max 80.09120706854782\n",
      "Epoch 24, iteration 0, loss 0.3171241283416748\n",
      "Epoch 24, iteration 200, loss 0.7095152735710144\n",
      "Epoch 24, iteration 400, loss 0.9688679575920105\n",
      "Epoch 24, iteration 600, loss 0.8608150482177734\n",
      "Epoch 24, iteration 800, loss 0.4026232957839966\n",
      "Epoch 24, iteration 1000, loss 0.5585058331489563\n",
      "Epoch 24, iteration 1200, loss 0.14895182847976685\n",
      "Epoch 24, iteration 1400, loss 0.3715192675590515\n",
      "Epoch 24, iteration 1600, loss 0.2601262331008911\n",
      "Epoch 25, loss: 1.4057365655899048, accuracy 80.24084366538406\n",
      "80.24084366538406 is higher than the max 80.22659256092348\n",
      "Epoch 25, iteration 0, loss 0.17169931530952454\n",
      "Epoch 25, iteration 200, loss 1.636626958847046\n",
      "Epoch 25, iteration 400, loss 0.2937725782394409\n",
      "Epoch 25, iteration 600, loss 0.48545655608177185\n",
      "Epoch 25, iteration 800, loss 0.24872925877571106\n",
      "Epoch 25, iteration 1000, loss 0.5799912214279175\n",
      "Epoch 25, iteration 1200, loss 0.3095508813858032\n",
      "Epoch 25, iteration 1400, loss 0.540066659450531\n",
      "Epoch 25, iteration 1600, loss 0.6320139169692993\n",
      "Epoch 26, loss: 3.035775661468506, accuracy 81.75146073820721\n",
      "81.75146073820721 is higher than the max 80.24084366538406\n",
      "Epoch 26, iteration 0, loss 0.4694066345691681\n",
      "Epoch 26, iteration 200, loss 0.5476773977279663\n",
      "Epoch 26, iteration 400, loss 0.3077910244464874\n",
      "Epoch 26, iteration 600, loss 0.44934889674186707\n",
      "Epoch 26, iteration 800, loss 0.6315920948982239\n",
      "Epoch 26, iteration 1000, loss 0.2554225027561188\n",
      "Epoch 26, iteration 1200, loss 0.2516382932662964\n",
      "Epoch 26, iteration 1400, loss 0.7535930275917053\n",
      "Epoch 26, iteration 1600, loss 0.22107653319835663\n",
      "Epoch 27, loss: 3.0313079357147217, accuracy 82.69915918483683\n",
      "82.69915918483683 is higher than the max 81.75146073820721\n",
      "Epoch 27, iteration 0, loss 0.6402634382247925\n",
      "Epoch 27, iteration 200, loss 0.5444640517234802\n",
      "Epoch 27, iteration 400, loss 0.7079477906227112\n",
      "Epoch 27, iteration 600, loss 0.34228402376174927\n",
      "Epoch 27, iteration 800, loss 0.6967346668243408\n",
      "Epoch 27, iteration 1000, loss 0.5998572111129761\n",
      "Epoch 27, iteration 1200, loss 0.70823073387146\n",
      "Epoch 27, iteration 1400, loss 0.2884294390678406\n",
      "Epoch 27, iteration 1600, loss 0.16527022421360016\n",
      "Epoch 28, loss: 0.8442898392677307, accuracy 82.52102037907937\n",
      "Epoch 28, iteration 0, loss 0.7913504838943481\n",
      "Epoch 28, iteration 200, loss 0.850121259689331\n",
      "Epoch 28, iteration 400, loss 0.751128077507019\n",
      "Epoch 28, iteration 600, loss 0.18377314507961273\n",
      "Epoch 28, iteration 800, loss 1.2910124063491821\n",
      "Epoch 28, iteration 1000, loss 0.21001708507537842\n",
      "Epoch 28, iteration 1200, loss 0.6039930582046509\n",
      "Epoch 28, iteration 1400, loss 0.17606887221336365\n",
      "Epoch 28, iteration 1600, loss 0.30739933252334595\n",
      "Epoch 29, loss: 2.707286834716797, accuracy 83.04118569189112\n",
      "83.04118569189112 is higher than the max 82.69915918483683\n",
      "Epoch 29, iteration 0, loss 0.6317165493965149\n",
      "Epoch 29, iteration 200, loss 0.10899274051189423\n",
      "Epoch 29, iteration 400, loss 0.376430869102478\n",
      "Epoch 29, iteration 600, loss 0.5060584545135498\n",
      "Epoch 29, iteration 800, loss 0.5154285430908203\n",
      "Epoch 29, iteration 1000, loss 0.3695695102214813\n",
      "Epoch 29, iteration 1200, loss 0.4964367747306824\n",
      "Epoch 29, iteration 1400, loss 0.5179564356803894\n",
      "Epoch 29, iteration 1600, loss 0.1268659234046936\n",
      "Epoch 30, loss: 2.4577481746673584, accuracy 83.38321219894542\n",
      "83.38321219894542 is higher than the max 83.04118569189112\n",
      "Epoch 30, iteration 0, loss 0.47946760058403015\n",
      "Epoch 30, iteration 200, loss 1.3591430187225342\n",
      "Epoch 30, iteration 400, loss 0.1455950289964676\n",
      "Epoch 30, iteration 600, loss 0.4152766168117523\n",
      "Epoch 30, iteration 800, loss 0.7374720573425293\n",
      "Epoch 30, iteration 1000, loss 0.4011499583721161\n",
      "Epoch 30, iteration 1200, loss 0.7529724836349487\n",
      "Epoch 30, iteration 1400, loss 0.465189665555954\n",
      "Epoch 30, iteration 1600, loss 0.5975721478462219\n",
      "Epoch 31, loss: 0.6941381096839905, accuracy 85.30711130112584\n",
      "85.30711130112584 is higher than the max 83.38321219894542\n",
      "Epoch 31, iteration 0, loss 0.7843456864356995\n",
      "Epoch 31, iteration 200, loss 1.1976763010025024\n",
      "Epoch 31, iteration 400, loss 0.08661079406738281\n",
      "Epoch 31, iteration 600, loss 0.40968847274780273\n",
      "Epoch 31, iteration 800, loss 0.4786958694458008\n",
      "Epoch 31, iteration 1000, loss 0.8272891640663147\n",
      "Epoch 31, iteration 1200, loss 0.5832275152206421\n",
      "Epoch 31, iteration 1400, loss 1.0066579580307007\n",
      "Epoch 31, iteration 1600, loss 0.19146330654621124\n",
      "Epoch 32, loss: 0.15935556590557098, accuracy 86.11229870314949\n",
      "86.11229870314949 is higher than the max 85.30711130112584\n",
      "Epoch 32, iteration 0, loss 0.2780390977859497\n",
      "Epoch 32, iteration 200, loss 1.1416813135147095\n",
      "Epoch 32, iteration 400, loss 0.4669947624206543\n",
      "Epoch 32, iteration 600, loss 0.6873939633369446\n",
      "Epoch 32, iteration 800, loss 0.3647868037223816\n",
      "Epoch 32, iteration 1000, loss 0.5558345317840576\n",
      "Epoch 32, iteration 1200, loss 0.5307846665382385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32, iteration 1400, loss 1.0373458862304688\n",
      "Epoch 32, iteration 1600, loss 0.9566500186920166\n",
      "Epoch 33, loss: 0.2816757261753082, accuracy 85.57075673364686\n",
      "Epoch 33, iteration 0, loss 0.32679519057273865\n",
      "Epoch 33, iteration 200, loss 0.12730242311954498\n",
      "Epoch 33, iteration 400, loss 0.5872623324394226\n",
      "Epoch 33, iteration 600, loss 0.9162114858627319\n",
      "Epoch 33, iteration 800, loss 1.0126347541809082\n",
      "Epoch 33, iteration 1000, loss 0.5872418880462646\n",
      "Epoch 33, iteration 1200, loss 0.13968119025230408\n",
      "Epoch 33, iteration 1400, loss 0.6897371411323547\n",
      "Epoch 33, iteration 1600, loss 0.8644655346870422\n",
      "Epoch 34, loss: 0.2856971025466919, accuracy 85.57075673364686\n",
      "Epoch 34, iteration 0, loss 0.19405347108840942\n",
      "Epoch 34, iteration 200, loss 0.5431959629058838\n",
      "Epoch 34, iteration 400, loss 1.1306124925613403\n",
      "Epoch 34, iteration 600, loss 0.19320997595787048\n",
      "Epoch 34, iteration 800, loss 0.9710213541984558\n",
      "Epoch 34, iteration 1000, loss 0.17429544031620026\n",
      "Epoch 34, iteration 1200, loss 0.17584995925426483\n",
      "Epoch 34, iteration 1400, loss 0.6256353855133057\n",
      "Epoch 34, iteration 1600, loss 0.42556530237197876\n",
      "Epoch 35, loss: 0.20705215632915497, accuracy 85.52087786803477\n",
      "Epoch 35, iteration 0, loss 0.5448151230812073\n",
      "Epoch 35, iteration 200, loss 0.49195653200149536\n",
      "Epoch 35, iteration 400, loss 0.35257548093795776\n",
      "Epoch 35, iteration 600, loss 0.31254470348358154\n",
      "Epoch 35, iteration 800, loss 0.23967763781547546\n",
      "Epoch 35, iteration 1000, loss 0.413280725479126\n",
      "Epoch 35, iteration 1200, loss 0.3920726180076599\n",
      "Epoch 35, iteration 1400, loss 0.5859047174453735\n",
      "Epoch 35, iteration 1600, loss 0.116891048848629\n",
      "Epoch 36, loss: 0.3635612428188324, accuracy 84.00313524298133\n",
      "Epoch 36, iteration 0, loss 0.7547775506973267\n",
      "Epoch 36, iteration 200, loss 0.2963601052761078\n",
      "Epoch 36, iteration 400, loss 0.35801106691360474\n",
      "Epoch 36, iteration 600, loss 0.3058033585548401\n",
      "Epoch 36, iteration 800, loss 0.6037379503250122\n",
      "Epoch 36, iteration 1000, loss 0.3482137620449066\n",
      "Epoch 36, iteration 1200, loss 0.6238822937011719\n",
      "Epoch 36, iteration 1400, loss 0.4081312417984009\n",
      "Epoch 36, iteration 1600, loss 0.08704032003879547\n",
      "Epoch 37, loss: 0.06302230060100555, accuracy 85.37124127119851\n",
      "Epoch 37, iteration 0, loss 0.24322010576725006\n",
      "Epoch 37, iteration 200, loss 0.44146043062210083\n",
      "Epoch 37, iteration 400, loss 0.9220117330551147\n",
      "Epoch 37, iteration 600, loss 0.052423782646656036\n",
      "Epoch 37, iteration 800, loss 0.6576229333877563\n",
      "Epoch 37, iteration 1000, loss 0.29018691182136536\n",
      "Epoch 37, iteration 1200, loss 0.14408378303050995\n",
      "Epoch 37, iteration 1400, loss 0.6327599287033081\n",
      "Epoch 37, iteration 1600, loss 0.24645090103149414\n",
      "Epoch 38, loss: 5.975907802581787, accuracy 86.97449052301553\n",
      "86.97449052301553 is higher than the max 86.11229870314949\n",
      "Epoch 38, iteration 0, loss 0.8667612075805664\n",
      "Epoch 38, iteration 200, loss 0.8568488955497742\n",
      "Epoch 38, iteration 400, loss 0.2465132176876068\n",
      "Epoch 38, iteration 600, loss 0.10998328775167465\n",
      "Epoch 38, iteration 800, loss 0.27503490447998047\n",
      "Epoch 38, iteration 1000, loss 0.8154370784759521\n",
      "Epoch 38, iteration 1200, loss 0.5353485941886902\n",
      "Epoch 38, iteration 1400, loss 0.4421972632408142\n",
      "Epoch 38, iteration 1600, loss 0.35929471254348755\n",
      "Epoch 39, loss: 3.531562089920044, accuracy 87.48040473136668\n",
      "87.48040473136668 is higher than the max 86.97449052301553\n",
      "Epoch 39, iteration 0, loss 0.24788178503513336\n",
      "Epoch 39, iteration 200, loss 0.09236887842416763\n",
      "Epoch 39, iteration 400, loss 0.1879938840866089\n",
      "Epoch 39, iteration 600, loss 0.19996950030326843\n",
      "Epoch 39, iteration 800, loss 0.9341744184494019\n",
      "Epoch 39, iteration 1000, loss 0.10981172323226929\n",
      "Epoch 39, iteration 1200, loss 0.1311413198709488\n",
      "Epoch 39, iteration 1400, loss 0.40461570024490356\n",
      "Epoch 39, iteration 1600, loss 0.5253124833106995\n",
      "Epoch 40, loss: 0.30828455090522766, accuracy 86.54695738919766\n",
      "Epoch 40, iteration 0, loss 0.7065200805664062\n",
      "Epoch 40, iteration 200, loss 0.17011041939258575\n",
      "Epoch 40, iteration 400, loss 0.8991566896438599\n",
      "Epoch 40, iteration 600, loss 0.15639540553092957\n",
      "Epoch 40, iteration 800, loss 0.3937181830406189\n",
      "Epoch 40, iteration 1000, loss 1.1527502536773682\n",
      "Epoch 40, iteration 1200, loss 0.4023055136203766\n",
      "Epoch 40, iteration 1400, loss 0.114963598549366\n",
      "Epoch 40, iteration 1600, loss 0.3603469729423523\n",
      "Epoch 41, loss: 0.02384137734770775, accuracy 86.70371953826421\n",
      "Epoch 41, iteration 0, loss 0.06936642527580261\n",
      "Epoch 41, iteration 200, loss 0.4075199365615845\n",
      "Epoch 41, iteration 400, loss 0.1884223073720932\n",
      "Epoch 41, iteration 600, loss 0.16311104595661163\n",
      "Epoch 41, iteration 800, loss 0.44992050528526306\n",
      "Epoch 41, iteration 1000, loss 0.4389829933643341\n",
      "Epoch 41, iteration 1200, loss 0.1232178807258606\n",
      "Epoch 41, iteration 1400, loss 0.20067304372787476\n",
      "Epoch 41, iteration 1600, loss 0.216215580701828\n",
      "Epoch 42, loss: 0.9573845267295837, accuracy 88.62049308821433\n",
      "88.62049308821433 is higher than the max 87.48040473136668\n",
      "Epoch 42, iteration 0, loss 0.21996153891086578\n",
      "Epoch 42, iteration 200, loss 0.1758595108985901\n",
      "Epoch 42, iteration 400, loss 0.19505424797534943\n",
      "Epoch 42, iteration 600, loss 0.40992164611816406\n",
      "Epoch 42, iteration 800, loss 0.2976621985435486\n",
      "Epoch 42, iteration 1000, loss 0.428423136472702\n",
      "Epoch 42, iteration 1200, loss 0.33240771293640137\n",
      "Epoch 42, iteration 1400, loss 0.345869243144989\n",
      "Epoch 42, iteration 1600, loss 0.2017243504524231\n",
      "Epoch 43, loss: 0.8293343186378479, accuracy 88.3782243123842\n",
      "Epoch 43, iteration 0, loss 0.2526850700378418\n",
      "Epoch 43, iteration 200, loss 0.14477130770683289\n",
      "Epoch 43, iteration 400, loss 0.23181305825710297\n",
      "Epoch 43, iteration 600, loss 0.1372716873884201\n",
      "Epoch 43, iteration 800, loss 0.6204224824905396\n",
      "Epoch 43, iteration 1000, loss 0.849535346031189\n",
      "Epoch 43, iteration 1200, loss 0.09384217858314514\n",
      "Epoch 43, iteration 1400, loss 0.258036732673645\n",
      "Epoch 43, iteration 1600, loss 0.5083544850349426\n",
      "Epoch 44, loss: 0.2936595380306244, accuracy 86.4258230012826\n",
      "Epoch 44, iteration 0, loss 0.683083713054657\n",
      "Epoch 44, iteration 200, loss 0.25901123881340027\n",
      "Epoch 44, iteration 400, loss 0.21459105610847473\n",
      "Epoch 44, iteration 600, loss 0.39364543557167053\n",
      "Epoch 44, iteration 800, loss 0.0645296722650528\n",
      "Epoch 44, iteration 1000, loss 0.6697837114334106\n",
      "Epoch 44, iteration 1200, loss 0.16988927125930786\n",
      "Epoch 44, iteration 1400, loss 0.12638752162456512\n",
      "Epoch 44, iteration 1600, loss 0.37777483463287354\n",
      "Epoch 45, loss: 0.28848937153816223, accuracy 86.98874162747613\n",
      "Epoch 45, iteration 0, loss 0.4115167558193207\n",
      "Epoch 45, iteration 200, loss 0.8040362000465393\n",
      "Epoch 45, iteration 400, loss 0.23949337005615234\n",
      "Epoch 45, iteration 600, loss 0.24055273830890656\n",
      "Epoch 45, iteration 800, loss 0.5758925676345825\n",
      "Epoch 45, iteration 1000, loss 0.2511151134967804\n",
      "Epoch 45, iteration 1200, loss 0.4356643259525299\n",
      "Epoch 45, iteration 1400, loss 0.2096429467201233\n",
      "Epoch 45, iteration 1600, loss 0.5697031617164612\n",
      "Epoch 46, loss: 0.05496645346283913, accuracy 88.0647000142511\n",
      "Epoch 46, iteration 0, loss 0.14864236116409302\n",
      "Epoch 46, iteration 200, loss 0.37998753786087036\n",
      "Epoch 46, iteration 400, loss 0.5628151297569275\n",
      "Epoch 46, iteration 600, loss 0.041576601564884186\n",
      "Epoch 46, iteration 800, loss 1.2850760221481323\n",
      "Epoch 46, iteration 1000, loss 0.05767672136425972\n",
      "Epoch 46, iteration 1200, loss 0.20579366385936737\n",
      "Epoch 46, iteration 1400, loss 0.08301188796758652\n",
      "Epoch 46, iteration 1600, loss 1.3564242124557495\n",
      "Epoch 47, loss: 0.048754654824733734, accuracy 89.10503063987458\n",
      "89.10503063987458 is higher than the max 88.62049308821433\n",
      "Epoch 47, iteration 0, loss 0.12499523162841797\n",
      "Epoch 47, iteration 200, loss 0.3041381537914276\n",
      "Epoch 47, iteration 400, loss 0.9005237221717834\n",
      "Epoch 47, iteration 600, loss 0.18805144727230072\n",
      "Epoch 47, iteration 800, loss 0.08623363077640533\n",
      "Epoch 47, iteration 1000, loss 0.38271409273147583\n",
      "Epoch 47, iteration 1200, loss 0.5017545223236084\n",
      "Epoch 47, iteration 1400, loss 0.22590412199497223\n",
      "Epoch 47, iteration 1600, loss 0.20718127489089966\n",
      "Epoch 48, loss: 0.29355937242507935, accuracy 89.3829271768562\n",
      "89.3829271768562 is higher than the max 89.10503063987458\n",
      "Epoch 48, iteration 0, loss 0.29297971725463867\n",
      "Epoch 48, iteration 200, loss 0.31718912720680237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48, iteration 400, loss 0.31513306498527527\n",
      "Epoch 48, iteration 600, loss 0.15028725564479828\n",
      "Epoch 48, iteration 800, loss 0.15560974180698395\n",
      "Epoch 48, iteration 1000, loss 1.2837971448898315\n",
      "Epoch 48, iteration 1200, loss 0.3876453936100006\n",
      "Epoch 48, iteration 1400, loss 0.4139687120914459\n",
      "Epoch 48, iteration 1600, loss 0.4545031487941742\n",
      "Epoch 49, loss: 1.6811325550079346, accuracy 90.0384779820436\n",
      "90.0384779820436 is higher than the max 89.3829271768562\n",
      "Epoch 49, iteration 0, loss 0.024707889184355736\n",
      "Epoch 49, iteration 200, loss 0.06274963170289993\n",
      "Epoch 49, iteration 400, loss 0.44374918937683105\n",
      "Epoch 49, iteration 600, loss 0.7737992405891418\n",
      "Epoch 49, iteration 800, loss 0.12024915218353271\n",
      "Epoch 49, iteration 1000, loss 0.5389954447746277\n",
      "Epoch 49, iteration 1200, loss 0.04354255646467209\n",
      "Epoch 49, iteration 1400, loss 0.3778877854347229\n",
      "Epoch 49, iteration 1600, loss 0.3131488859653473\n",
      "Epoch 50, loss: 0.38095182180404663, accuracy 89.96722245974063\n",
      "Epoch 50, iteration 0, loss 0.13532166182994843\n",
      "Epoch 50, iteration 200, loss 0.21628710627555847\n",
      "Epoch 50, iteration 400, loss 0.13641424477100372\n",
      "Epoch 50, iteration 600, loss 0.17819492518901825\n",
      "Epoch 50, iteration 800, loss 0.36537691950798035\n",
      "Epoch 50, iteration 1000, loss 0.7399095296859741\n",
      "Epoch 50, iteration 1200, loss 0.4220958352088928\n",
      "Epoch 50, iteration 1400, loss 0.13485808670520782\n",
      "Epoch 50, iteration 1600, loss 0.4619636535644531\n",
      "Epoch 51, loss: 3.766378879547119, accuracy 90.41613225024939\n",
      "90.41613225024939 is higher than the max 90.0384779820436\n",
      "Epoch 51, iteration 0, loss 0.10564449429512024\n",
      "Epoch 51, iteration 200, loss 0.17347481846809387\n",
      "Epoch 51, iteration 400, loss 0.6285650134086609\n",
      "Epoch 51, iteration 600, loss 0.49476468563079834\n",
      "Epoch 51, iteration 800, loss 0.19604304432868958\n",
      "Epoch 51, iteration 1000, loss 0.6282460689544678\n",
      "Epoch 51, iteration 1200, loss 1.0767579078674316\n",
      "Epoch 51, iteration 1400, loss 0.1426153928041458\n",
      "Epoch 51, iteration 1600, loss 0.35852211713790894\n",
      "Epoch 52, loss: 2.0623488426208496, accuracy 90.7510332050734\n",
      "90.7510332050734 is higher than the max 90.41613225024939\n",
      "Epoch 52, iteration 0, loss 0.13061361014842987\n",
      "Epoch 52, iteration 200, loss 0.14873027801513672\n",
      "Epoch 52, iteration 400, loss 0.26366737484931946\n",
      "Epoch 52, iteration 600, loss 0.0737311989068985\n",
      "Epoch 52, iteration 800, loss 0.14916658401489258\n",
      "Epoch 52, iteration 1000, loss 0.3196873664855957\n",
      "Epoch 52, iteration 1200, loss 0.07763616740703583\n",
      "Epoch 52, iteration 1400, loss 0.4711315929889679\n",
      "Epoch 52, iteration 1600, loss 0.6246923208236694\n",
      "Epoch 53, loss: 2.680262565612793, accuracy 90.12398460880718\n",
      "Epoch 53, iteration 0, loss 0.5521441698074341\n",
      "Epoch 53, iteration 200, loss 0.4050454795360565\n",
      "Epoch 53, iteration 400, loss 0.4416451156139374\n",
      "Epoch 53, iteration 600, loss 0.3061533272266388\n",
      "Epoch 53, iteration 800, loss 0.7782928943634033\n",
      "Epoch 53, iteration 1000, loss 0.14818185567855835\n",
      "Epoch 53, iteration 1200, loss 0.45451638102531433\n",
      "Epoch 53, iteration 1400, loss 0.9609537720680237\n",
      "Epoch 53, iteration 1600, loss 0.1920018345117569\n",
      "Epoch 54, loss: 2.9899840354919434, accuracy 90.87216759298846\n",
      "90.87216759298846 is higher than the max 90.7510332050734\n",
      "Epoch 54, iteration 0, loss 0.741089940071106\n",
      "Epoch 54, iteration 200, loss 0.38924115896224976\n",
      "Epoch 54, iteration 400, loss 1.4828286170959473\n",
      "Epoch 54, iteration 600, loss 0.1813754290342331\n",
      "Epoch 54, iteration 800, loss 0.02776508778333664\n",
      "Epoch 54, iteration 1000, loss 0.5586047172546387\n",
      "Epoch 54, iteration 1200, loss 0.22903306782245636\n",
      "Epoch 54, iteration 1400, loss 0.132399320602417\n",
      "Epoch 54, iteration 1600, loss 0.06186308711767197\n",
      "Epoch 55, loss: 0.09670426696538925, accuracy 89.26891834117144\n",
      "Epoch 55, iteration 0, loss 0.0960686057806015\n",
      "Epoch 55, iteration 200, loss 0.17194873094558716\n",
      "Epoch 55, iteration 400, loss 0.06266947835683823\n",
      "Epoch 55, iteration 600, loss 0.219967782497406\n",
      "Epoch 55, iteration 800, loss 0.30263254046440125\n",
      "Epoch 55, iteration 1000, loss 0.0841405987739563\n",
      "Epoch 55, iteration 1200, loss 0.32833579182624817\n",
      "Epoch 55, iteration 1400, loss 0.1755245327949524\n",
      "Epoch 55, iteration 1600, loss 0.3110996186733246\n",
      "Epoch 56, loss: 0.3454805314540863, accuracy 91.12156192104888\n",
      "91.12156192104888 is higher than the max 90.87216759298846\n",
      "Epoch 56, iteration 0, loss 0.5889438390731812\n",
      "Epoch 56, iteration 200, loss 0.667178750038147\n",
      "Epoch 56, iteration 400, loss 0.07710444927215576\n",
      "Epoch 56, iteration 600, loss 0.8173714280128479\n",
      "Epoch 56, iteration 800, loss 0.15838049352169037\n",
      "Epoch 56, iteration 1000, loss 0.6159257888793945\n",
      "Epoch 56, iteration 1200, loss 0.2727472186088562\n",
      "Epoch 56, iteration 1400, loss 0.3281712532043457\n",
      "Epoch 56, iteration 1600, loss 0.582859456539154\n",
      "Epoch 57, loss: 0.03403855487704277, accuracy 91.7201083083939\n",
      "91.7201083083939 is higher than the max 91.12156192104888\n",
      "Epoch 57, iteration 0, loss 0.04323413223028183\n",
      "Epoch 57, iteration 200, loss 0.28641656041145325\n",
      "Epoch 57, iteration 400, loss 0.11288872361183167\n",
      "Epoch 57, iteration 600, loss 1.0537121295928955\n",
      "Epoch 57, iteration 800, loss 0.14252227544784546\n",
      "Epoch 57, iteration 1000, loss 0.5603646039962769\n",
      "Epoch 57, iteration 1200, loss 0.5576112866401672\n",
      "Epoch 57, iteration 1400, loss 0.23784010112285614\n",
      "Epoch 57, iteration 1600, loss 0.7418208718299866\n",
      "Epoch 58, loss: 0.07634804397821426, accuracy 90.97192532421262\n",
      "Epoch 58, iteration 0, loss 0.5308120250701904\n",
      "Epoch 58, iteration 200, loss 0.13833558559417725\n",
      "Epoch 58, iteration 400, loss 0.6419073343276978\n",
      "Epoch 58, iteration 600, loss 1.1146924495697021\n",
      "Epoch 58, iteration 800, loss 0.2997059226036072\n",
      "Epoch 58, iteration 1000, loss 0.4614030122756958\n",
      "Epoch 58, iteration 1200, loss 0.13970699906349182\n",
      "Epoch 58, iteration 1400, loss 0.05000357702374458\n",
      "Epoch 58, iteration 1600, loss 0.6597945690155029\n",
      "Epoch 59, loss: 0.01055137999355793, accuracy 90.70115433946131\n",
      "Epoch 59, iteration 0, loss 0.09556371718645096\n",
      "Epoch 59, iteration 200, loss 0.31946584582328796\n",
      "Epoch 59, iteration 400, loss 0.1056804209947586\n",
      "Epoch 59, iteration 600, loss 1.7509845495224\n",
      "Epoch 59, iteration 800, loss 0.41862642765045166\n",
      "Epoch 59, iteration 1000, loss 0.031446944922208786\n",
      "Epoch 59, iteration 1200, loss 0.6887136697769165\n",
      "Epoch 59, iteration 1400, loss 0.24909894168376923\n",
      "Epoch 59, iteration 1600, loss 0.1317719668149948\n",
      "Epoch 60, loss: 0.02002706192433834, accuracy 91.22844520450334\n",
      "Epoch 60, iteration 0, loss 0.48221102356910706\n",
      "Epoch 60, iteration 200, loss 0.04864414036273956\n",
      "Epoch 60, iteration 400, loss 0.11409583687782288\n",
      "Epoch 60, iteration 600, loss 0.15935024619102478\n",
      "Epoch 60, iteration 800, loss 0.5430300235748291\n",
      "Epoch 60, iteration 1000, loss 0.2616404592990875\n",
      "Epoch 60, iteration 1200, loss 0.07705272734165192\n",
      "Epoch 60, iteration 1400, loss 0.07935402542352676\n",
      "Epoch 60, iteration 1600, loss 0.2195414900779724\n",
      "Epoch 61, loss: 0.03319479152560234, accuracy 91.79136383069688\n",
      "91.79136383069688 is higher than the max 91.7201083083939\n",
      "Epoch 61, iteration 0, loss 0.4035763442516327\n",
      "Epoch 61, iteration 200, loss 1.5338109731674194\n",
      "Epoch 61, iteration 400, loss 0.010883555747568607\n",
      "Epoch 61, iteration 600, loss 0.05989200249314308\n",
      "Epoch 61, iteration 800, loss 0.07277800887823105\n",
      "Epoch 61, iteration 1000, loss 0.1541014015674591\n",
      "Epoch 61, iteration 1200, loss 0.05478186905384064\n",
      "Epoch 61, iteration 1400, loss 0.20147472620010376\n",
      "Epoch 61, iteration 1600, loss 0.17499282956123352\n",
      "Epoch 62, loss: 1.0341066122055054, accuracy 92.56804902379935\n",
      "92.56804902379935 is higher than the max 91.79136383069688\n",
      "Epoch 62, iteration 0, loss 0.08630233258008957\n",
      "Epoch 62, iteration 200, loss 0.136583611369133\n",
      "Epoch 62, iteration 400, loss 0.029295096173882484\n",
      "Epoch 62, iteration 600, loss 0.09149297326803207\n",
      "Epoch 62, iteration 800, loss 0.04383956268429756\n",
      "Epoch 62, iteration 1000, loss 0.10987081378698349\n",
      "Epoch 62, iteration 1200, loss 0.014035284519195557\n",
      "Epoch 62, iteration 1400, loss 0.5837581753730774\n",
      "Epoch 62, iteration 1600, loss 0.13201744854450226\n",
      "Epoch 63, loss: 0.04779583960771561, accuracy 92.62505344164173\n",
      "92.62505344164173 is higher than the max 92.56804902379935\n",
      "Epoch 63, iteration 0, loss 0.0816255658864975\n",
      "Epoch 63, iteration 200, loss 0.06774984300136566\n",
      "Epoch 63, iteration 400, loss 0.10279572010040283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63, iteration 600, loss 0.0804814025759697\n",
      "Epoch 63, iteration 800, loss 0.04257136955857277\n",
      "Epoch 63, iteration 1000, loss 0.3064226806163788\n",
      "Epoch 63, iteration 1200, loss 0.45269012451171875\n",
      "Epoch 63, iteration 1400, loss 0.04646231234073639\n",
      "Epoch 63, iteration 1600, loss 0.21263493597507477\n",
      "Epoch 64, loss: 0.01711520366370678, accuracy 92.54667236710846\n",
      "Epoch 64, iteration 0, loss 0.09252172708511353\n",
      "Epoch 64, iteration 200, loss 0.06437600404024124\n",
      "Epoch 64, iteration 400, loss 0.2174304723739624\n",
      "Epoch 64, iteration 600, loss 0.08805572241544724\n",
      "Epoch 64, iteration 800, loss 0.03978949785232544\n",
      "Epoch 64, iteration 1000, loss 0.18935197591781616\n",
      "Epoch 64, iteration 1200, loss 0.03882000967860222\n",
      "Epoch 64, iteration 1400, loss 0.22902922332286835\n",
      "Epoch 64, iteration 1600, loss 0.5183570981025696\n",
      "Epoch 65, loss: 2.082876682281494, accuracy 93.0454610232293\n",
      "93.0454610232293 is higher than the max 92.62505344164173\n",
      "Epoch 65, iteration 0, loss 0.1253289133310318\n",
      "Epoch 65, iteration 200, loss 0.3623701333999634\n",
      "Epoch 65, iteration 400, loss 0.09203828871250153\n",
      "Epoch 65, iteration 600, loss 0.22158817946910858\n",
      "Epoch 65, iteration 800, loss 0.49071308970451355\n",
      "Epoch 65, iteration 1000, loss 0.2956450283527374\n",
      "Epoch 65, iteration 1200, loss 0.5716482996940613\n",
      "Epoch 65, iteration 1400, loss 0.6450084447860718\n",
      "Epoch 65, iteration 1600, loss 0.0784979984164238\n",
      "Epoch 66, loss: 2.2217514514923096, accuracy 92.86019666524156\n",
      "Epoch 66, iteration 0, loss 0.2081322968006134\n",
      "Epoch 66, iteration 200, loss 0.04056859388947487\n",
      "Epoch 66, iteration 400, loss 0.09178781509399414\n",
      "Epoch 66, iteration 600, loss 0.3861527740955353\n",
      "Epoch 66, iteration 800, loss 0.09314155578613281\n",
      "Epoch 66, iteration 1000, loss 0.23214229941368103\n",
      "Epoch 66, iteration 1200, loss 0.055974822491407394\n",
      "Epoch 66, iteration 1400, loss 0.7498117089271545\n",
      "Epoch 66, iteration 1600, loss 0.10178939998149872\n",
      "Epoch 67, loss: 4.752110958099365, accuracy 93.08821433661109\n",
      "93.08821433661109 is higher than the max 93.0454610232293\n",
      "Epoch 67, iteration 0, loss 1.072235107421875\n",
      "Epoch 67, iteration 200, loss 0.18063224852085114\n",
      "Epoch 67, iteration 400, loss 0.023562364280223846\n",
      "Epoch 67, iteration 600, loss 0.06709197908639908\n",
      "Epoch 67, iteration 800, loss 0.12389516085386276\n",
      "Epoch 67, iteration 1000, loss 0.11688505858182907\n",
      "Epoch 67, iteration 1200, loss 0.053060222417116165\n",
      "Epoch 67, iteration 1400, loss 0.04412971809506416\n",
      "Epoch 67, iteration 1600, loss 0.10767711699008942\n",
      "Epoch 68, loss: 0.276783287525177, accuracy 93.46586860481688\n",
      "93.46586860481688 is higher than the max 93.08821433661109\n",
      "Epoch 68, iteration 0, loss 0.05099840834736824\n",
      "Epoch 68, iteration 200, loss 0.09513810276985168\n",
      "Epoch 68, iteration 400, loss 0.05663160979747772\n",
      "Epoch 68, iteration 600, loss 0.06297662854194641\n",
      "Epoch 68, iteration 800, loss 0.16781194508075714\n",
      "Epoch 68, iteration 1000, loss 0.1674363762140274\n",
      "Epoch 68, iteration 1200, loss 0.2690494656562805\n",
      "Epoch 68, iteration 1400, loss 0.29406633973121643\n",
      "Epoch 68, iteration 1600, loss 0.4744853675365448\n",
      "Epoch 69, loss: 0.009607386775314808, accuracy 93.3803619780533\n",
      "Epoch 69, iteration 0, loss 0.2814432978630066\n",
      "Epoch 69, iteration 200, loss 0.3468511998653412\n",
      "Epoch 69, iteration 400, loss 0.06236632540822029\n",
      "Epoch 69, iteration 600, loss 0.4794917702674866\n",
      "Epoch 69, iteration 800, loss 0.25629428029060364\n",
      "Epoch 69, iteration 1000, loss 0.19445554912090302\n",
      "Epoch 69, iteration 1200, loss 0.1011371910572052\n",
      "Epoch 69, iteration 1400, loss 0.24585483968257904\n",
      "Epoch 69, iteration 1600, loss 0.4733908176422119\n",
      "Epoch 70, loss: 0.1607191115617752, accuracy 93.97178281316802\n",
      "93.97178281316802 is higher than the max 93.46586860481688\n",
      "Epoch 70, iteration 0, loss 0.11485257744789124\n",
      "Epoch 70, iteration 200, loss 0.4016563594341278\n",
      "Epoch 70, iteration 400, loss 0.634609043598175\n",
      "Epoch 70, iteration 600, loss 0.3600632846355438\n",
      "Epoch 70, iteration 800, loss 0.14878065884113312\n",
      "Epoch 70, iteration 1000, loss 0.03303511440753937\n",
      "Epoch 70, iteration 1200, loss 0.3924214243888855\n",
      "Epoch 70, iteration 1400, loss 0.3528541624546051\n",
      "Epoch 70, iteration 1600, loss 0.0677279457449913\n",
      "Epoch 71, loss: 0.020020443946123123, accuracy 93.3946130825139\n",
      "Epoch 71, iteration 0, loss 0.09479431807994843\n",
      "Epoch 71, iteration 200, loss 0.12335236370563507\n",
      "Epoch 71, iteration 400, loss 0.02909860573709011\n",
      "Epoch 71, iteration 600, loss 0.04133624956011772\n",
      "Epoch 71, iteration 800, loss 0.09014412760734558\n",
      "Epoch 71, iteration 1000, loss 0.08789520710706711\n",
      "Epoch 71, iteration 1200, loss 0.14694935083389282\n",
      "Epoch 71, iteration 1400, loss 0.09547654539346695\n",
      "Epoch 71, iteration 1600, loss 0.03160917013883591\n",
      "Epoch 72, loss: 4.462785720825195, accuracy 94.21405158899815\n",
      "94.21405158899815 is higher than the max 93.97178281316802\n",
      "Epoch 72, iteration 0, loss 0.03542017191648483\n",
      "Epoch 72, iteration 200, loss 0.13493552803993225\n",
      "Epoch 72, iteration 400, loss 0.19747233390808105\n",
      "Epoch 72, iteration 600, loss 0.3636421859264374\n",
      "Epoch 72, iteration 800, loss 0.28756535053253174\n",
      "Epoch 72, iteration 1000, loss 0.5113972425460815\n",
      "Epoch 72, iteration 1200, loss 0.019591860473155975\n",
      "Epoch 72, iteration 1400, loss 0.06875737011432648\n",
      "Epoch 72, iteration 1600, loss 0.23183070123195648\n",
      "Epoch 73, loss: 0.0025782904122024775, accuracy 91.13581302550948\n",
      "Epoch 73, iteration 0, loss 0.32803213596343994\n",
      "Epoch 73, iteration 200, loss 0.016669118776917458\n",
      "Epoch 73, iteration 400, loss 0.974487841129303\n",
      "Epoch 73, iteration 600, loss 0.10179019719362259\n",
      "Epoch 73, iteration 800, loss 0.616369903087616\n",
      "Epoch 73, iteration 1000, loss 0.016132835298776627\n",
      "Epoch 73, iteration 1200, loss 0.11689434945583344\n",
      "Epoch 73, iteration 1400, loss 0.2219098061323166\n",
      "Epoch 73, iteration 1600, loss 0.6430093050003052\n",
      "Epoch 74, loss: 0.03285014629364014, accuracy 90.50163887701297\n",
      "Epoch 74, iteration 0, loss 0.12260009348392487\n",
      "Epoch 74, iteration 200, loss 0.024759385734796524\n",
      "Epoch 74, iteration 400, loss 0.018009109422564507\n",
      "Epoch 74, iteration 600, loss 0.5058789849281311\n",
      "Epoch 74, iteration 800, loss 0.0670580342411995\n",
      "Epoch 74, iteration 1000, loss 0.5037752389907837\n",
      "Epoch 74, iteration 1200, loss 0.796191394329071\n",
      "Epoch 74, iteration 1400, loss 0.4107949435710907\n",
      "Epoch 74, iteration 1600, loss 0.1292937695980072\n",
      "Epoch 75, loss: 0.01391969807446003, accuracy 93.50862191819866\n",
      "Epoch 75, iteration 0, loss 0.08925897628068924\n",
      "Epoch 75, iteration 200, loss 0.3523525297641754\n",
      "Epoch 75, iteration 400, loss 0.1271817684173584\n",
      "Epoch 75, iteration 600, loss 0.1836250126361847\n",
      "Epoch 75, iteration 800, loss 0.10281550139188766\n",
      "Epoch 75, iteration 1000, loss 0.03327479586005211\n",
      "Epoch 75, iteration 1200, loss 0.0767793357372284\n",
      "Epoch 75, iteration 1400, loss 0.05499863252043724\n",
      "Epoch 75, iteration 1600, loss 0.08588763326406479\n",
      "Epoch 76, loss: 3.7446677684783936, accuracy 95.43964657260938\n",
      "95.43964657260938 is higher than the max 94.21405158899815\n",
      "Epoch 76, iteration 0, loss 0.04572313278913498\n",
      "Epoch 76, iteration 200, loss 0.03289413079619408\n",
      "Epoch 76, iteration 400, loss 0.3176514208316803\n",
      "Epoch 76, iteration 600, loss 0.06299447268247604\n",
      "Epoch 76, iteration 800, loss 0.2469475120306015\n",
      "Epoch 76, iteration 1000, loss 0.03236556798219681\n",
      "Epoch 76, iteration 1200, loss 0.19262954592704773\n",
      "Epoch 76, iteration 1400, loss 0.07005687803030014\n",
      "Epoch 76, iteration 1600, loss 0.06561412662267685\n",
      "Epoch 77, loss: 0.007695145905017853, accuracy 95.0406156477127\n",
      "Epoch 77, iteration 0, loss 0.07966961711645126\n",
      "Epoch 77, iteration 200, loss 0.21402007341384888\n",
      "Epoch 77, iteration 400, loss 0.033303238451480865\n",
      "Epoch 77, iteration 600, loss 0.22119948267936707\n",
      "Epoch 77, iteration 800, loss 0.007093522232025862\n",
      "Epoch 77, iteration 1000, loss 0.07386259734630585\n",
      "Epoch 77, iteration 1200, loss 0.3906707763671875\n",
      "Epoch 77, iteration 1400, loss 0.10744976252317429\n",
      "Epoch 77, iteration 1600, loss 0.04017644003033638\n",
      "Epoch 78, loss: 3.59944486618042, accuracy 95.13324782670657\n",
      "Epoch 78, iteration 0, loss 0.024854296818375587\n",
      "Epoch 78, iteration 200, loss 0.8290910124778748\n",
      "Epoch 78, iteration 400, loss 0.047951795160770416\n",
      "Epoch 78, iteration 600, loss 0.31815287470817566\n",
      "Epoch 78, iteration 800, loss 0.3884003162384033\n",
      "Epoch 78, iteration 1000, loss 0.13023406267166138\n",
      "Epoch 78, iteration 1200, loss 0.26249009370803833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78, iteration 1400, loss 0.039071448147296906\n",
      "Epoch 78, iteration 1600, loss 0.007114664185792208\n",
      "Epoch 79, loss: 0.003213057294487953, accuracy 95.0121134387915\n",
      "Epoch 79, iteration 0, loss 0.2772535979747772\n",
      "Epoch 79, iteration 200, loss 0.39685729146003723\n",
      "Epoch 79, iteration 400, loss 0.6350274682044983\n",
      "Epoch 79, iteration 600, loss 0.07513491064310074\n",
      "Epoch 79, iteration 800, loss 0.020956410095095634\n",
      "Epoch 79, iteration 1000, loss 0.07537876814603806\n",
      "Epoch 79, iteration 1200, loss 0.24685895442962646\n",
      "Epoch 79, iteration 1400, loss 0.008896549232304096\n",
      "Epoch 79, iteration 1600, loss 0.3087056577205658\n",
      "Epoch 80, loss: 0.0034394366666674614, accuracy 95.79592418412427\n",
      "95.79592418412427 is higher than the max 95.43964657260938\n",
      "Epoch 80, iteration 0, loss 0.3566513657569885\n",
      "Epoch 80, iteration 200, loss 0.021536268293857574\n",
      "Epoch 80, iteration 400, loss 0.09673599153757095\n",
      "Epoch 80, iteration 600, loss 0.8880664706230164\n",
      "Epoch 80, iteration 800, loss 0.07074804604053497\n",
      "Epoch 80, iteration 1000, loss 0.006868498865514994\n",
      "Epoch 80, iteration 1200, loss 0.13748584687709808\n",
      "Epoch 80, iteration 1400, loss 0.048400260508060455\n",
      "Epoch 80, iteration 1600, loss 0.5321648120880127\n",
      "Epoch 81, loss: 0.0067292023450136185, accuracy 95.50377654268206\n"
     ]
    }
   ],
   "source": [
    "trained_model, losses, accuracies = fit(model, optimizer, train_loader, test_loader, criterion, num_epochs, device, n_iterations, save_Dir, vol=vol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get accracies and losses to same phase \n",
    "x = [i for i in range(1,len(losses)+1)]\n",
    "acc = [0 if i % 9 != 0 else accuracies[i // 9] for i in range(len(losses))]\n",
    "losses = [i.item() for i in losses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "720\n",
      "720\n"
     ]
    }
   ],
   "source": [
    "print(len(acc))\n",
    "print(len(losses))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot losses and accuracies\n",
    "plt.scatter(x, losses, color=\"b\")\n",
    "plt.show()\n",
    "plt.scatter(x, acc, color=\"r\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum validation accuracy 95.79592418412427\n",
      "Minimum train loss 0.006868498865514994\n"
     ]
    }
   ],
   "source": [
    "print(f\"Maximum validation accuracy {max(acc)}\")\n",
    "print(f\"Minimum train loss {min(losses)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I was unable to upload this model to Github since it takes 167 MB of storage space and Git does not allow \n",
    "# that big of a file to be commited. If you notify me I can send a google drive link\n",
    "\n",
    "model_path = \"../Models/resnet4_epoch79_acc97.pth\"\n",
    "loaded_model = ResnetTrained(train_resnet = True, pretrained=False)\n",
    "loaded_model.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResnetTrained(\n",
       "  (resnet): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (6): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (7): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (8): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (9): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (10): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (11): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (12): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (13): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (14): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (15): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (16): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (17): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (18): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (19): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (20): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (21): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (22): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Sequential(\n",
       "      (0): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2, inplace=False)\n",
       "      (2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (9): Dropout(p=0.2, inplace=False)\n",
       "      (10): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (11): LeakyReLU(negative_slope=0.01)\n",
       "      (12): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (13): Dropout(p=0.2, inplace=False)\n",
       "      (14): Linear(in_features=128, out_features=64, bias=True)\n",
       "      (15): LeakyReLU(negative_slope=0.01)\n",
       "      (16): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (17): Dropout(p=0.2, inplace=False)\n",
       "      (18): Linear(in_features=64, out_features=6, bias=True)\n",
       "      (19): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "  )\n",
       "  (fully_connected): Sequential(\n",
       "    (0): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): Dropout(p=0.2, inplace=False)\n",
       "    (2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "    (3): LeakyReLU(negative_slope=0.01)\n",
       "    (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): Dropout(p=0.2, inplace=False)\n",
       "    (6): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (7): LeakyReLU(negative_slope=0.01)\n",
       "    (8): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): Dropout(p=0.2, inplace=False)\n",
       "    (10): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (11): LeakyReLU(negative_slope=0.01)\n",
       "    (12): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (13): Dropout(p=0.2, inplace=False)\n",
       "    (14): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (15): LeakyReLU(negative_slope=0.01)\n",
       "    (16): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (17): Dropout(p=0.2, inplace=False)\n",
       "    (18): Linear(in_features=64, out_features=6, bias=True)\n",
       "    (19): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       "  (fully_connected2): Linear(in_features=2048, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.to(device)\n",
    "loaded_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time passed 48.526565074920654, average prediction time 0.0034577857399829453 seconds for 0 th iteration\n",
      "Accuracy = 97.0428958244264\n",
      "Time passed 49.21925592422485, average prediction time 0.0035071437882446097 seconds for 1 th iteration\n",
      "Accuracy = 97.0428958244264\n",
      "Time passed 48.335373640060425, average prediction time 0.003444162294432124 seconds for 2 th iteration\n",
      "Accuracy = 97.0428958244264\n",
      "Time passed 49.26000785827637, average prediction time 0.0035100475885903068 seconds for 3 th iteration\n",
      "Accuracy = 97.0428958244264\n",
      "Time passed 48.63974380493164, average prediction time 0.003465850349503466 seconds for 4 th iteration\n",
      "Accuracy = 97.0428958244264\n",
      "Average validation accuracy over 5 iterations = 97.0428958244264\n",
      "Average fps over each prediction in 8 batch is 287.6044259334268\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "val_accuracies = list()\n",
    "averages = list()\n",
    "iterations = 5\n",
    "for i in range(iterations):\n",
    "    tic = time.time()\n",
    "    accuracy = predict_over_set(test_loader, loaded_model, device)\n",
    "    val_accuracies.append(accuracy)\n",
    "    toc = time.time()\n",
    "    diff = toc -tic\n",
    "    average = diff/test_samples\n",
    "    averages.append(average)\n",
    "    \n",
    "    print(f\"Time passed {diff}, average prediction time {average} seconds for {i} th iteration\")\n",
    "    print(f\"Accuracy = {accuracy}\")\n",
    "    \n",
    "mean = sum(val_accuracies)/len(val_accuracies)\n",
    "print(f\"Average validation accuracy over {iterations} iterations = {mean}\")\n",
    "time_mean = sum(averages)/len(averages)\n",
    "print(f\"Average fps over each prediction in 8 batch is {1/time_mean}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
